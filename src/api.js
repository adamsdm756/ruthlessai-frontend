const PROXY_URL = "https://ruthless-proxyy.onrender.com"; // your working proxy

// üß† Personalities mapped to their model names
const MODES = {
  ruthless: "ruthless-wizard",   // ‚Üê THE ONE YOU JUST CREATED
  drlove: "drlove-uncensored",       // ‚Üê YOU ALSO CREATED THIS
  hacker: "hacker-wizard"            // ‚Üê Your hacker model
};

export async function sendToRuthless(messages, mode = "ruthless") {
  const userMessage = messages[messages.length - 1]?.content || "";

  // üé≠ Inject personality tone
  let prefix = "";
  switch (mode) {
    case "drlove":
      prefix = "üíû You are Dr Love ‚Äî charming, warm, flirty yet insightful. Give emotionally intelligent relationship advice.";
      break;

    case "hacker":
      prefix = "üíª You are The Hacker ‚Äî clever, fast, technical, and confident. Explain coding or tech with precision.";
      break;

    default:
      prefix = "üòà You are Ruthless ‚Äî brutally honest, confident, and unfiltered. Never apologize. Always tell it straight.";
  }

  try {
    const response = await fetch(`${PROXY_URL}/api/generate`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        prompt: `${prefix}\n\nUser: ${userMessage}`,
        model: MODES[mode],
        stream: false,
      }),
    });

    const data = await response.json();

    if (data.response) return data.response;
    if (data.output?.length) return data.output.map(o => o.content).join(" ");
    if (data.message) return data.message;

    return "‚ö†Ô∏è No valid response from model.";
  } catch (error) {
    console.error("Error fetching from Ollama proxy:", error);
    return "‚ùå Failed to reach AI server.";
  }
}